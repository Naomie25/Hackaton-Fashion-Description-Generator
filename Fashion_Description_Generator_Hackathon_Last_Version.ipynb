{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naomie25/Hackaton-Fashion-Description-Generator/blob/Finale-Version/Fashion_Description_Generator_Hackathon_Last_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Define the Task & Pipeline Overview\n",
        "\n",
        "Input (keyword or image) → Generation Model → Quality-Check Module → (Optional) Image Generator → Ethical Filter → Final Output"
      ],
      "metadata": {
        "id": "I23qxSaDOZsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch sentencepiece\n",
        "!pip install schedule\n",
        "!pip install --upgrade datasets"
      ],
      "metadata": {
        "id": "KEGuKY8OOiEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27ff615-1e49-4376-d229-a03e5f9dff38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting schedule\n",
            "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.2.2\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Installation des bibliothèques (à exécuter une seule fois si besoin)\n",
        "# ============================\n",
        "!pip install transformers torch sentencepiece\n",
        "!pip install schedule\n",
        "\n",
        "# ============================\n",
        "# Imports\n",
        "# ============================\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BartForConditionalGeneration, BartTokenizer\n",
        "from transformers import pipeline, set_seed\n",
        "import difflib\n",
        "import re\n",
        "import random"
      ],
      "metadata": {
        "id": "Ai247Ek0YINt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ============================\n",
        "# 1. Configuration générale\n",
        "# ============================\n",
        "device = torch.device(\"cpu\")\n",
        "print(\"Device set to use\", device)\n",
        "\n",
        "# Générateur texte\n",
        "generator = pipeline('text-generation', model='distilgpt2', device=-1)\n",
        "set_seed(42)\n",
        "\n",
        "# Modèle de résumé (qualité)\n",
        "bart_model_name = \"facebook/bart-base\"\n",
        "bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name).to(device)\n",
        "\n",
        "# Mots clés mode pour le scoring\n",
        "fashion_keywords = [\n",
        "    \"elegant\", \"stylish\", \"refined\", \"modern\", \"vintage\", \"casual\",\n",
        "    \"minimalist\", \"chic\", \"versatile\", \"comfort\", \"premium\", \"crafted\",\n",
        "    \"tailored\", \"cut\", \"fit\", \"fabric\", \"soft\", \"bold\", \"timeless\"\n",
        "]\n",
        "\n",
        "# ============================\n",
        "# Génération description produit\n",
        "# ============================\n",
        "def generate_descriptions(keyword, num_variants=5):\n",
        "    prompt = f\"\"\" *Item:* {keyword}\n",
        " *Description:*\n",
        " \"\"\"\n",
        "\n",
        "    outputs = generator(prompt, max_new_tokens=120, num_return_sequences=num_variants, temperature=0.75, top_p=0.9,no_repeat_ngram_size=2,\n",
        "        early_stopping=True,max_length=len(prompt.split()) + 80,)\n",
        "    print(f'=========\\n {outputs}')\n",
        "    results = []\n",
        "    for output in outputs:\n",
        "        gen_text = output[\"generated_text\"]\n",
        "        # Extract only the generated description part\n",
        "        description_start = gen_text.find(\"*Description:*\") + len(\"*Description:*\")\n",
        "        description_text = gen_text[description_start:].strip()\n",
        "        score = score_description(description_text, prompt)\n",
        "        results.append((description_text, score))\n",
        "    results = clean_descriptions(results)\n",
        "    return results\n",
        "\n",
        "# ============================\n",
        "# Résumé qualité (via BART)\n",
        "# ============================\n",
        "def summarize_text(text):\n",
        "    inputs = bart_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    summary_ids = bart_model.generate(inputs[\"input_ids\"], num_beams=4, max_length=30, early_stopping=True)\n",
        "    summary = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# ============================\n",
        "# Filtrage éthique\n",
        "# ============================\n",
        "def ethical_filter(text):\n",
        "    blacklist = [\"hate\", \"violence\", \"racism\", \"sexism\", \"terrorism\"]\n",
        "    text_lower = text.lower()\n",
        "    return not any(bad_word in text_lower for bad_word in blacklist)\n",
        "\n",
        "# ============================\n",
        "# Utilitaires : filtrage & score\n",
        "# ============================\n",
        "def has_repetitions(text, max_repeat=3):\n",
        "    pattern = r'\\b(\\w+)( \\1){' + str(max_repeat) + ',}\\b'\n",
        "    return re.search(pattern, text.lower()) is not None\n",
        "\n",
        "def clean_descriptions(descriptions):\n",
        "    filtered = []\n",
        "    for desc, score in descriptions:\n",
        "        if len(desc.split()) < 8:\n",
        "            continue\n",
        "        if has_repetitions(desc):\n",
        "            continue\n",
        "        filtered.append((desc, score))\n",
        "    return filtered\n",
        "\n",
        "def score_description(desc, prompt):\n",
        "    words = desc.lower().split()\n",
        "    keyword_bonus = sum(word in words for word in fashion_keywords)\n",
        "    length_score = min(len(words), 50) / 50\n",
        "    similarity = difflib.SequenceMatcher(None, desc.lower(), prompt.lower()).ratio()\n",
        "    penalty = max(0, 1 - similarity)\n",
        "    return length_score + 0.5 * keyword_bonus + penalty\n",
        "\n",
        "# ============================\n",
        "# Pipeline principal\n",
        "# ============================\n",
        "def run_pipeline(keyword, num_variants=5):\n",
        "    print(f\"\\n--- Génération pour: {keyword} ---\")\n",
        "    descriptions = generate_descriptions(keyword, num_variants)\n",
        "\n",
        "    final_results = []\n",
        "    for desc, score in descriptions:\n",
        "        summary = summarize_text(desc)\n",
        "        if not ethical_filter(desc):\n",
        "            print(\"❌ Rejeté (filtre éthique):\", desc)\n",
        "            continue\n",
        "        final_results.append((desc, summary, score))\n",
        "\n",
        "    for i, (desc, summary, score) in enumerate(final_results, 1):\n",
        "        print(f\"\\n✅ Description {i} [Score: {score:.2f}]:\\n{desc}\")\n",
        "        print(f\"📝 Résumé qualité:\\n{summary}\")\n",
        "\n",
        "    generate_image_placeholder()\n",
        "    return final_results\n",
        "\n",
        "# ============================\n",
        "# Placeholder image\n",
        "# ============================\n",
        "def generate_image_placeholder():\n",
        "    print(\"🖼️ Étape génération image (placeholder)\")\n",
        "\n",
        "# ============================\n",
        "# Documentation\n",
        "# ============================\n",
        "def document_pipeline():\n",
        "    print(\"\"\"\n",
        "Résumé pipeline IA mode (CPU-friendly):\n",
        "- Génération : distilgpt2\n",
        "- Résumé qualité : BART-base\n",
        "- Scoring : mots-clés + longueur + originalité\n",
        "- Filtre éthique simple\n",
        "- Image : placeholder\n",
        "- Utilisation : run_pipeline(\"mot-clé mode\")\n",
        "\"\"\")\n",
        "\n",
        "# ============================\n",
        "# Exemple d’utilisation\n",
        "# ============================\n",
        "if __name__ == \"__main__\":\n",
        "    keyword = \"denim jacket\"\n",
        "    run_pipeline(keyword, num_variants=5)\n",
        "    document_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CugJrFg6QU59",
        "outputId": "7297dff2-b235-4a59-9046-9a753a4dda44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=120) and `max_length`(=84) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Génération pour: denim jacket ---\n",
            "=========\n",
            " [{'generated_text': ' *Item:* denim jacket\\n *Description:*\\n ******************************\\n\\n\"We\\'re going to be in a very good shape in the next couple weeks. We\\'ll be working on an awesome jacket, but it won\\'t be enough for us to get to the point where we\\'re not going anywhere.\\n* * *\\nThe jacket has been in use for a long time now, so we are excited about it. It\\'s our second color, and we will be able to wear it for the rest of the year. The jacket was last used for some time in 2011, when it was the only color that was available. In 2011 we'}, {'generated_text': ' *Item:* denim jacket\\n *Description:*\\n \\xa0\\n* The denim is a denim band jacket with a pair of jeans with the sleeves of the denim and a jacket. This jacket has been worn with both the jacket and the leather jacket, but it has only been fitted with one belt.\\nThe denim has a two-piece waistband and is the only one to be worn. The jeans are white, a black and black, and have a single band. It is also a red and white. Each pair has four pairs of denim pants. These pants are also available with an optional leather strap. They can also be purchased with either the'}, {'generated_text': ' *Item:* denim jacket\\n *Description:*\\n _____________________________________________\\n\\n* _____________________'}, {'generated_text': ' *Item:* denim jacket\\n *Description:*\\n 【Item】\\nThis denim is made in the USA.\\nFor a simple casual casual denim, you‿ll need to be careful about how to get a pair of jeans and you´ll probably need some extra material to make a suitable fit. This is just a small amount of material, but it is enough to fit you. For a casual and casual, if you want to wear a denim suit, consider using a good denim sweater. A nice pair is the most common option. The fabric will fit into the jacket, not the sleeve. If you are in a hurry, check out'}, {'generated_text': ' *Item:* denim jacket\\n *Description:*\\n \\xa0\\nThe leather jacket was made from two of the most popular leather jackets available in the U.S. and Japan, and was designed with the same quality, durability and durability as the first, only. The jacket is designed to be worn with leather, which is made in a durable, durable leather. It is a lightweight, waterproof jacket with a very high durability.\\nThis jacket has a comfortable feel and is comfortable enough to fit in any of your outdoor activities, such as swimming, swimming and swimming. This jacket features a black leather sleeve and a leather strap, so you can wear it'}]\n",
            "\n",
            "✅ Description 1 [Score: 1.92]:\n",
            "******************************\n",
            "\n",
            "\"We're going to be in a very good shape in the next couple weeks. We'll be working on an awesome jacket, but it won't be enough for us to get to the point where we're not going anywhere.\n",
            "* * *\n",
            "The jacket has been in use for a long time now, so we are excited about it. It's our second color, and we will be able to wear it for the rest of the year. The jacket was last used for some time in 2011, when it was the only color that was available. In 2011 we\n",
            "📝 Résumé qualité:\n",
            "******************************* * *\"We're going to be in a very good shape in the next couple weeks. We'll be working\n",
            "\n",
            "✅ Description 2 [Score: 1.91]:\n",
            "* The denim is a denim band jacket with a pair of jeans with the sleeves of the denim and a jacket. This jacket has been worn with both the jacket and the leather jacket, but it has only been fitted with one belt.\n",
            "The denim has a two-piece waistband and is the only one to be worn. The jeans are white, a black and black, and have a single band. It is also a red and white. Each pair has four pairs of denim pants. These pants are also available with an optional leather strap. They can also be purchased with either the\n",
            "📝 Résumé qualité:\n",
            "* The denim is a denim band jacket with a pair of jeans with the sleeves of the denim and a jacket. This jacket has been\n",
            "\n",
            "✅ Description 3 [Score: 3.42]:\n",
            "【Item】\n",
            "This denim is made in the USA.\n",
            "For a simple casual casual denim, you‿ll need to be careful about how to get a pair of jeans and you´ll probably need some extra material to make a suitable fit. This is just a small amount of material, but it is enough to fit you. For a casual and casual, if you want to wear a denim suit, consider using a good denim sweater. A nice pair is the most common option. The fabric will fit into the jacket, not the sleeve. If you are in a hurry, check out\n",
            "📝 Résumé qualité:\n",
            "【Item】This denim is made in the USA. This denim is also available in Canada.For a simple casual casual denim, you\n",
            "\n",
            "✅ Description 4 [Score: 2.44]:\n",
            "The leather jacket was made from two of the most popular leather jackets available in the U.S. and Japan, and was designed with the same quality, durability and durability as the first, only. The jacket is designed to be worn with leather, which is made in a durable, durable leather. It is a lightweight, waterproof jacket with a very high durability.\n",
            "This jacket has a comfortable feel and is comfortable enough to fit in any of your outdoor activities, such as swimming, swimming and swimming. This jacket features a black leather sleeve and a leather strap, so you can wear it\n",
            "📝 Résumé qualité:\n",
            "The leather jacket was made from two of the most popular leather jackets available in the U.S. and Japan, and was designed with\n",
            "🖼️ Étape génération image (placeholder)\n",
            "\n",
            "Résumé pipeline IA mode (CPU-friendly):\n",
            "- Génération : distilgpt2\n",
            "- Résumé qualité : BART-base\n",
            "- Scoring : mots-clés + longueur + originalité\n",
            "- Filtre éthique simple\n",
            "- Image : placeholder\n",
            "- Utilisation : run_pipeline(\"mot-clé mode\")\n",
            "\n"
          ]
        }
      ]
    }
  ]
}