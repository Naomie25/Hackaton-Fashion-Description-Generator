{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naomie25/Hackaton-Fashion-Description-Generator/blob/FINALE-VERSION/Finale_Fashion_Description_Generator_Hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Define the Task & Pipeline Overview\n",
        "\n",
        "Input (keyword or image) → Generation Model → Quality-Check Module → (Optional) Image Generator → Ethical Filter → Final Output"
      ],
      "metadata": {
        "id": "I23qxSaDOZsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch sentencepiece\n",
        "!pip install schedule\n",
        "!pip install --upgrade datasets"
      ],
      "metadata": {
        "id": "KEGuKY8OOiEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27ff615-1e49-4376-d229-a03e5f9dff38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting schedule\n",
            "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.2.2\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Installation des bibliothèques (à exécuter une seule fois si besoin)\n",
        "# ============================\n",
        "!pip install transformers torch sentencepiece\n",
        "!pip install schedule\n",
        "\n",
        "# ============================\n",
        "# Imports\n",
        "# ============================\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BartForConditionalGeneration, BartTokenizer\n",
        "from transformers import pipeline, set_seed\n",
        "import difflib\n",
        "import re\n",
        "import random"
      ],
      "metadata": {
        "id": "Ai247Ek0YINt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    pipeline,\n",
        "    set_seed,\n",
        "    BartTokenizer,\n",
        "    BartForConditionalGeneration\n",
        ")\n",
        "import difflib\n",
        "import re\n",
        "\n",
        "# ============================\n",
        "# 1. Configuration Générale\n",
        "# ============================\n",
        "device = torch.device(\"cpu\")\n",
        "print(\"✅ Device set to use\", device)\n",
        "\n",
        "# Générateur de texte\n",
        "generator = pipeline('text-generation', model='distilgpt2', device=-1)\n",
        "set_seed(42)\n",
        "\n",
        "# Modèle de résumé qualité\n",
        "bart_model_name = \"facebook/bart-base\"\n",
        "bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name).to(device)\n",
        "\n",
        "# Liste de mots-clés mode pour le scoring\n",
        "fashion_keywords = [\n",
        "    \"elegant\", \"stylish\", \"refined\", \"modern\", \"vintage\", \"casual\",\n",
        "    \"minimalist\", \"chic\", \"versatile\", \"comfort\", \"premium\", \"crafted\",\n",
        "    \"tailored\", \"cut\", \"fit\", \"fabric\", \"soft\", \"bold\", \"timeless\"\n",
        "]\n",
        "\n",
        "# ============================\n",
        "# 2. Génération de descriptions\n",
        "# ============================\n",
        "def generate_descriptions(keyword, num_variants=5):\n",
        "    prompt = f\"\"\"*Item:* {keyword}\\n*Description:*\"\"\"\n",
        "\n",
        "    outputs = generator(\n",
        "        prompt,\n",
        "        max_new_tokens=120,\n",
        "        num_return_sequences=num_variants,\n",
        "        temperature=0.75,\n",
        "        top_p=0.9,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    results = []\n",
        "    for output in outputs:\n",
        "        gen_text = output[\"generated_text\"]\n",
        "        # Récupération de la portion générée après \"*Description:*\"\n",
        "        description_start = gen_text.find(\"*Description:*\") + len(\"*Description:*\")\n",
        "        description_text = gen_text[description_start:].strip()\n",
        "        score = score_description(description_text, prompt)\n",
        "        results.append((description_text, score))\n",
        "\n",
        "    results = clean_descriptions(results)\n",
        "    return results\n",
        "\n",
        "# ============================\n",
        "# 3. Résumé qualité (BART)\n",
        "# ============================\n",
        "def summarize_text(text):\n",
        "    inputs = bart_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    summary_ids = bart_model.generate(inputs[\"input_ids\"], num_beams=4, max_length=30, early_stopping=True)\n",
        "    summary = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# ============================\n",
        "# 4. Filtrage Éthique\n",
        "# ============================\n",
        "def ethical_filter(text):\n",
        "    blacklist = [\"hate\", \"violence\", \"racism\", \"sexism\", \"terrorism\"]\n",
        "    text_lower = text.lower()\n",
        "    return not any(bad_word in text_lower for bad_word in blacklist)\n",
        "\n",
        "# ============================\n",
        "# 5. Score et Nettoyage\n",
        "# ============================\n",
        "def has_repetitions(text, max_repeat=3):\n",
        "    pattern = r'\\b(\\w+)( \\1){' + str(max_repeat) + ',}\\b'\n",
        "    return re.search(pattern, text.lower()) is not None\n",
        "\n",
        "def clean_descriptions(descriptions):\n",
        "    filtered = []\n",
        "    for desc, score in descriptions:\n",
        "        if len(desc.split()) < 8:\n",
        "            continue\n",
        "        if has_repetitions(desc):\n",
        "            continue\n",
        "        filtered.append((desc, score))\n",
        "    return filtered\n",
        "\n",
        "def score_description(desc, prompt):\n",
        "    words = desc.lower().split()\n",
        "    keyword_bonus = sum(word in words for word in fashion_keywords)\n",
        "    length_score = min(len(words), 50) / 50\n",
        "    similarity = difflib.SequenceMatcher(None, desc.lower(), prompt.lower()).ratio()\n",
        "    penalty = max(0, 1 - similarity)\n",
        "    return length_score + 0.5 * keyword_bonus + penalty\n",
        "\n",
        "# ============================\n",
        "# 6. Pipeline principal\n",
        "# ============================\n",
        "def run_pipeline(keyword, num_variants=5):\n",
        "    print(f\"\\n--- Génération pour: {keyword} ---\")\n",
        "    descriptions = generate_descriptions(keyword, num_variants)\n",
        "\n",
        "    final_results = []\n",
        "    for desc, score in descriptions:\n",
        "        summary = summarize_text(desc)\n",
        "        if not ethical_filter(desc):\n",
        "            print(\"❌ Rejeté (filtre éthique):\", desc)\n",
        "            continue\n",
        "        final_results.append((desc, summary, score))\n",
        "\n",
        "    for i, (desc, summary, score) in enumerate(final_results, 1):\n",
        "        print(f\"\\n✅ Description {i} [Score: {score:.2f}]:\\n{desc}\")\n",
        "        print(f\"📝 Résumé qualité:\\n{summary}\")\n",
        "\n",
        "    generate_image_placeholder()\n",
        "    return final_results\n",
        "\n",
        "# ============================\n",
        "# 7. Image (placeholder)\n",
        "# ============================\n",
        "def generate_image_placeholder():\n",
        "    print(\"🖼️ Étape génération image (placeholder)\")\n",
        "\n",
        "# ============================\n",
        "# 8. Documentation pipeline\n",
        "# ============================\n",
        "def document_pipeline():\n",
        "    print(\"\"\"\n",
        "📌 Pipeline IA - Générateur de descriptions mode\n",
        "Étapes :\n",
        "1. Prompt → DistilGPT2 → Génération brute\n",
        "2. Résumé avec BART → Vérifie la qualité\n",
        "3. Filtrage éthique simple\n",
        "4. Score = longueur + mots-clés + originalité\n",
        "5. Image (placeholder)\n",
        "Utilisation : run_pipeline(\"mot-clé\")\n",
        "\"\"\")\n",
        "\n",
        "# ============================\n",
        "# 9. Exemple d’utilisation\n",
        "# ============================\n",
        "if __name__ == \"__main__\":\n",
        "    keyword = \"denim jacket\"\n",
        "    run_pipeline(keyword, num_variants=5)\n",
        "    document_pipeline()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CugJrFg6QU59",
        "outputId": "71cea9f1-c233-4a7f-f616-4e36f9cc6b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Génération pour: denim jacket ---\n",
            "\n",
            "✅ Description 1 [Score: 2.88]:\n",
            "The denim jackets are hand made from cotton and cotton. The jacket is made with cotton fabric, which is woven to fit snugly into the back of the jacket.\n",
            "Item Description:Item :* leather jacketItemType:&& fabricItemName:+* fabric ItemType :& cottonItemDescription:-* clothingItemSize:%& woolItemColor:0:5%* garmentItemWidth:2:1%+%%\n",
            "\n",
            "- All items are made in the same color. All item types are produced in a different color, and will be rolled together.\n",
            "\n",
            "Item type\n",
            "📝 Résumé qualité:\n",
            "The denim jackets are hand made from cotton and cotton. The jacket is made with cotton fabric, which is woven to fit snugly into\n",
            "\n",
            "✅ Description 2 [Score: 1.92]:\n",
            "The first garment is a denim sweatshirt with a very lightweight material with the top section of the jacket. The garment features the color of a wool shirt, a pair of leather pants, and a large gold band.\n",
            "It features a full-length black band with two gold bands. It features leather socks, black and white. There is also a button-down button up top. This garment has the back pocket and button down top that will be held down on the side of your pants. These pants are designed to be worn with no seams or seams. You can change the size of\n",
            "📝 Résumé qualité:\n",
            "The first garment is a denim sweatshirt with a very lightweight material with the top section of the jacket. The garment features the color of\n",
            "\n",
            "✅ Description 3 [Score: 1.85]:\n",
            "This jacket was made from denim jackets, which are similar to jeans, but with different colors.\n",
            "-\n",
            "All denim, with no color. (In the original, it was the only black denim)\n",
            "I don't think any other denim is similar. It's very similar, and has a different feel and feel. I would say it's the best denim.\n",
            "\n",
            "-\n",
            "📝 Résumé qualité:\n",
            "This jacket was made from denim jackets, which are similar to jeans, but with different colors. It's a black-and-white\n",
            "\n",
            "✅ Description 4 [Score: 1.92]:\n",
            "This garment was originally made by the U.S. Department of Labor, which was founded in 1958. The garment is made of cotton and is a very durable garment. This garment has been custom made in the United States, with no other materials available.\n",
            "The garment will not be worn at the workplace or on the field.\n",
            "📝 Résumé qualité:\n",
            "This garment was originally made by the U.S. Department of Labor, which was founded in 1958. The garment is made of cotton\n",
            "\n",
            "✅ Description 5 [Score: 1.94]:\n",
            "The leather jacket was made of two of the finest leather jackets from the legendary Levi Strauss Company. This jacket has been worn by many of our finest designers, including Levi's founder, Levi, and Levi.\n",
            "In addition to the leather, this jacket is a classic Levi Levi jacket with a unique look and appearance. The jacket features a jacket that comes with two different layers of leather to help you feel comfortable. It comes in a durable leather sleeve, a white leather coat, cotton jacket, leather-lined leather and a leather wrap. These two jackets are unique and unique to Levi and are\n",
            "📝 Résumé qualité:\n",
            "The leather jacket was made of two of the finest leather jackets from the legendary Levi Strauss Company. This jacket has been worn by many of\n",
            "🖼️ Étape génération image (placeholder)\n",
            "\n",
            "📌 Pipeline IA - Générateur de descriptions mode\n",
            "Étapes :\n",
            "1. Prompt → DistilGPT2 → Génération brute\n",
            "2. Résumé avec BART → Vérifie la qualité\n",
            "3. Filtrage éthique simple\n",
            "4. Score = longueur + mots-clés + originalité\n",
            "5. Image (placeholder)\n",
            "Utilisation : run_pipeline(\"mot-clé\")\n",
            "\n"
          ]
        }
      ]
    }
  ]
}